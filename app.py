import streamlit as st
import torch
import numpy as np
import google.generativeai as genai
from PIL import Image, ImageOps
import mediapipe as mp
import cv2
from tensorflow.keras.models import load_model
import os
import suno
from PIL import Image
from torchvision.transforms.functional import to_tensor, to_pil_image
from model import Generator
import requests
from streamlit_lottie import st_lottie
import io
# Configure page
st.set_page_config(page_title="OmniVerse",page_icon='ğŸ¤—')
st.markdown("""
<style>
    /* Global styles */
    body {
        font-family: 'Arial', sans-serif;
        background-color: #f0f2f5;
        color: #333;
    }
    
    /* Header */
    .stApp > header {
        background: linear-gradient(135deg, #ff5f6d, #ffc371);
        color: white;
        border-bottom: none;
        padding: 20px;
        text-align: center;
    }
    
    /* Main content */
    .stApp > div:nth-child(2) {
        padding-top: 20px;
        padding-left: 20px;
        padding-right: 20px;
    }
    
    /* Sidebar */
    .sidebar .sidebar-content {
        background-color: #ffffff;
        border-right: 2px solid #e0e0e0;
        padding: 20px;
    }
    
    /* Buttons */
    .stButton>button {
        background-color: #ff6f61;
        color: white;
        border: none;
        border-radius: 20px;
        padding: 10px 24px;
        font-weight: 500;
        cursor: pointer;
    }
    .stButton>button:hover {
        background-color: #ff4d4d;
    }
    
    /* File uploader */
    .stFileUploader {
        border: 2px dashed #ff6f61;
        border-radius: 10px;
        padding: 20px;
        margin-top: 20px;
        text-align: center;
        background-color: #ffffff;
    }
    
    /* Chat messages */
    .chat-message {
        background-color: #ffffff;
        border: 1px solid #e0e0e0;
        border-radius: 10px;
        padding: 15px;
        margin-bottom: 15px;
    }
    .chat-message .message {
        color: #333;
    }
    
    /* Images */
    img {
        border-radius: 10px;
    }
    /* Vibrant title */
    .vibrant-title {
        font-family: 'Arial', sans-serif;
        font-size: 36px;
        font-weight: 700;
        color: #ff5f6d;
        text-align: center;
        margin-bottom: 20px;
    }
    /* Chat Input */
    .stChatInput>div>input {
        background-color: #ffffff;
        border: 2px solid #e0e0e0;
        border-radius: 20px;
        padding: 10px 24px;
    }
    
    /* Gradient text for chat messages */
    .gradient-text {
        background: linear-gradient(45deg, #405de6, #5851db, #833ab4, #c13584, #e1306c, #fd1d1d);
        color: transparent;
        background-clip: text;
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
    }
    
    
</style>
""", unsafe_allow_html=True)
st.markdown("""
<style>
.stSpinner > div > div {
    border-top-color: #FF4B4B !important;
}
</style>
""", unsafe_allow_html=True)

def load_lottie_url(url: str):
    r = requests.get(url)
    if r.status_code != 200:
        return None
    return r.json()

# Lottie animation
lottie_url = "https://assets5.lottiefiles.com/packages/lf20_V9t630.json"
lottie_json = load_lottie_url(lottie_url)

# Custom CSS
st.markdown("""
<style>
    [data-testid=stSidebar] {
        background-image: linear-gradient(135deg, rgba(221,77,21,1) 11%, rgba(218,148,233,1) 86%);
    }
    .sidebar-title {
        font-size: 30px !important;
        font-weight: bold;
        text-align: center;
        color: #ffffff;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.5);
    }
    .sidebar-subtitle {
        font-size: 20px !important;
        font-weight: bold;
        text-align: center;
        color: #ffd700;
        text-shadow: 1px 1px 2px rgba(0,0,0,0.3);
    }
    .sidebar-text {
        text-align: justify;
        color: #ffffff;
        background-color: rgba(0,0,0,0.1);
        padding: 10px;
        border-radius: 5px;
    }
    .feature-title {
        font-size: 18px !important;
        font-weight: bold;
        color: #ffd700;
        text-shadow: 1px 1px 2px rgba(0,0,0,0.3);
    }
</style>
""", unsafe_allow_html=True)

# Sidebar content
st.sidebar.markdown('<p class="sidebar-title">ğŸŒŸ OmniVerse Info</p>', unsafe_allow_html=True)

# Lottie animation
st_lottie(lottie_json, height=200, key="lottie")
st.sidebar.markdown('<p class="sidebar-text">OmniVerseëŠ” Gemini ëª¨ë¸ê³¼ FLUXë¥¼ í™œìš©í•˜ì—¬ íŒ¨ì…˜ ì¶”ì²œ ì´ë¯¸ì§€ ìƒì„±, ì™¸ëª¨ ì ìˆ˜ ì˜ˆì¸¡, ìŒì•… ìƒì„±, ì´ë¯¸ì§€ ì›¹íˆ°í™”, ê·¸ë¦¬ê³  ì´ë¯¸ì§€ ë¶„ì„ ê¸°ëŠ¥ì„ í†µí•©í•œ ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ì´ ëª¨ë“  ê¸°ëŠ¥ì€ Gemini ê¸°ìˆ ì„ ê¸°ë°˜ìœ¼ë¡œ í•˜ì—¬, ë³´ë‹¤ ì •êµí•˜ê³  ê°œì¸í™”ëœ ê²½í—˜ì„ ì œê³µí•©ë‹ˆë‹¤.</p>', unsafe_allow_html=True)

st.sidebar.markdown('<p class="sidebar-subtitle">ğŸš€ ì‚¬ìš© ë°©ë²•</p>', unsafe_allow_html=True)
features = [
    ("ğŸ’¬ Gemini ì±—ë´‡", "ë‹¤ì–‘í•œ ì§ˆë¬¸ì— ë‹µë³€í•˜ê³  ìœ ìš©í•œ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤. íŠ¹ì • ì£¼ì œì— ëŒ€í•œ ì§ˆë¬¸ë„ ê°€ëŠ¥í•˜ë‹ˆ í¸í•˜ê²Œ ì´ì•¼ê¸°í•´ë³´ì„¸ìš”!"),
    ("ğŸ” ë‚˜ì˜ ì™¸ëª¨ì ìˆ˜ëŠ”?", "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³  'ì™¸ëª¨ ë¶„ì„í•´ì¤˜'ë¥¼ ì…ë ¥í•´ë³´ì„¸ìš”. AIê°€ ì™¸ëª¨ë¥¼ ë¶„ì„í•´ ìƒˆë¡œìš´ ë§¤ë ¥ì„ ì°¾ì•„ë“œë¦½ë‹ˆë‹¤."),
    ("ğŸ¨ ì›¹íˆ° ì†ìœ¼ë¡œ", "'ì›¹íˆ°í™” í•´ì¤˜'ë¼ê³  ì…ë ¥í•˜ë©´, ì‚¬ì§„ì´ ì›¹íˆ° ì£¼ì¸ê³µì²˜ëŸ¼ ë³€ì‹ í•©ë‹ˆë‹¤."),
    ("ğŸ“Š ì´ë¯¸ì§€ ë¶„ì„", "'ì´ë¯¸ì§€ ë¶„ì„í•´ì¤˜'ë¥¼ ì…ë ¥í•´ ì‚¬ì§„ ì† ìˆ¨ê²¨ì§„ ì •ë³´ë¥¼ í™•ì¸í•´ë³´ì„¸ìš”."),
    ("ğŸµ AI ìŒì•… ìƒì„±", "ë‚˜ë§Œì˜ ìŒì•…ì´ í•„ìš”í•˜ë‹¤ë©´, ì´ë¯¸ì§€ë¥¼ ì˜¬ë¦¬ê³  'ìŒì•… ë§Œë“¤ì–´ì¤˜'ë¼ê³  í•´ë³´ì„¸ìš”."),
    ("ğŸ‘— AI íŒ¨ì…˜ ìŠ¤íƒ€ì¼ë¦¬ìŠ¤íŠ¸", "ë‚˜ì—ê²Œ ì–´ìš¸ë¦¬ëŠ” ìŠ¤íƒ€ì¼ì´ ê¶ê¸ˆí•˜ë‹¤ë©´, ì´ë¯¸ì§€ë¥¼ ì˜¬ë¦¬ê³  'íŒ¨ì…˜ ì¶”ì²œí•´ì¤˜'ë¥¼ ì…ë ¥í•´ë³´ì„¸ìš”.")
]

for title, description in features:
    st.sidebar.markdown(f'<p class="feature-title">{title}</p>', unsafe_allow_html=True)
    st.sidebar.markdown(f'<p class="sidebar-text">{description}</p>', unsafe_allow_html=True)


huggingface_api=os.environ["HUGGINGFACE_API_KEY"]
GEMINI_MODEL = 'gemini-1.5-flash'
@st.cache_resource
def load_models():
    genai.configure(api_key='AIzaSyDcq3ZfAUo1i6_24CelEizJftuEkaAPz38')
    gemini_model = genai.GenerativeModel(GEMINI_MODEL)
    facescore_model = load_model('facescore.h5',compile=False)
    webtoon_model=Generator()
    webtoon_model.load_state_dict(torch.load('./weights/face_paint_512_v2.pt', map_location="cpu"))
    webtoon_model.to('cpu').eval()
    return gemini_model, facescore_model, webtoon_model



mp_face_detection = mp.solutions.face_detection

def detect_and_crop_face(image):
    with mp_face_detection.FaceDetection(model_selection=1, min_detection_confidence=0.5) as face_detection:
        image_np = np.array(image)
        results = face_detection.process(image_np)
        if results.detections:
            detection = results.detections[0]
            bbox = detection.location_data.relative_bounding_box
            ih, iw, _ = image_np.shape
            xmin = int(bbox.xmin * iw)
            ymin = int(bbox.ymin * ih)
            width = int(bbox.width * iw)
            height = int(bbox.height * ih)
            xmax = xmin + width
            ymax = ymin + height
            face = image.crop((xmin, ymin, xmax, ymax))
            return face
        else:
            return None


def generate_chat_response(message, gemini_model):
    response = gemini_model.generate_content(message)
    return response.text

def analyze_image(image, gemini_model):
    prompt = """
    ì´ ì´ë¯¸ì§€ì— ëŒ€í•´ ìì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”. ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
    1. ì´ë¯¸ì§€ì—ì„œ ë³´ì´ëŠ” ì£¼ìš” ê°ì²´ë‚˜ ì‚¬ëŒë“¤
    2. ë°°ê²½ì´ë‚˜ ì¥ì†Œì— ëŒ€í•œ ì„¤ëª…
    3. ì´ë¯¸ì§€ì˜ ì „ì²´ì ì¸ ë¶„ìœ„ê¸°ë‚˜ ëŠë‚Œ
    4. ì´ë¯¸ì§€ì—ì„œ ì½ì„ ìˆ˜ ìˆëŠ” í…ìŠ¤íŠ¸ (ìˆëŠ” ê²½ìš°)
    5. ì´ë¯¸ì§€ì˜ ìƒ‰ìƒì´ë‚˜ êµ¬ë„ì— ëŒ€í•œ ê°„ë‹¨í•œ ì„¤ëª…
    6. ì´ë¯¸ì§€ê°€ ì „ë‹¬í•˜ë ¤ëŠ” ë©”ì‹œì§€ë‚˜ ì˜ë¯¸ (ìˆë‹¤ê³  ìƒê°ë˜ëŠ” ê²½ìš°)
    ë¶„ì„ ê²°ê³¼ë¥¼ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
    """
    
    response = gemini_model.generate_content([prompt, image])
    return response.text

def process_facescore(image, facescore_model, gemini_model):
    face = detect_and_crop_face(image)
    if face is None:
        return "ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì‹œë„í•´ ì£¼ì„¸ìš”."
    
    analysis = analyze_image(image, gemini_model)
    
    face_np = np.array(face)
    img_resized = cv2.resize(face_np, (350, 350))
    img_resized = img_resized.astype(np.float32) / 255.
    img_batch = np.expand_dims(img_resized, axis=0)
    score = facescore_model.predict(img_batch)
    
    if isinstance(score, np.ndarray) and score.size > 1:
        score = score[0]
    score = float(score)
    score = display_result(score)
    
    return f'### ì´ë¯¸ì§€ ë¶„ì„ ê²°ê³¼ ###\n\n{analysis}\n\n### ì™¸ëª¨ì ìˆ˜ ê²°ê³¼(1~5) ###\n\n{score}'


def generate_music(image, gemini_model, suno_cookie):
    st.info('3ë¶„ì •ë„ ì†Œìš”ë©ë‹ˆë‹¤!')
    face = detect_and_crop_face(image)
    if face is None:
        return "ì–¼êµ´ì´ ê°ì§€ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì´ë¯¸ì§€ë¥¼ ì‹œë„í•´ ì£¼ì„¸ìš”."
    
    prompt = """
    ì´ ì´ë¯¸ì§€ì— ëŒ€í•´ ìì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”. ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
    1. ì„±ë³„:
    2. ë‚˜ì´:
    3. í‘œì •:
    ë¶„ì„ ê²°ê³¼ë¥¼ í•œêµ­ì–´ë¡œ ê°„ëµí•˜ê²Œ ì œê³µí•´ì£¼ì„¸ìš”.
    """
    
    response = gemini_model.generate_content([prompt, image])
    music_path = generate_songs(response.text, suno_cookie)

    # ìŒì•… ì¬ìƒ
    st.audio(str(music_path), format='audio/wav')
    st.caption("Generated Music")
    
    # ìŒì•… íŒŒì¼ ì‚­ì œ
    if os.path.exists(music_path):
        os.remove(music_path)

    return "ìŒì•…ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤. ìœ„ì˜ í”Œë ˆì´ì–´ì—ì„œ ìŒì•…ì„ ë“¤ì–´ë³´ì„¸ìš”."

def generate_songs(result_output, suno_cookie):
    client = suno.Suno(cookie=suno_cookie)
    songs = client.generate(
        prompt=f'{result_output}', is_custom=False, wait_audio=True
    )
    
    # ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ
    file_path = client.download(song=songs[0])
    return file_path
def display_result(score):
    result = round(score, 1)+0.3
    messages = [
        ("'ìì‹ ê° í­ë°œ ì¤‘'ì…ë‹ˆë‹¤! ğŸ˜ ë‹¹ì‹ ì€ ìì‹ ì˜ ì™¸ëª¨ì— ëŒ€í•œ í™•ì‹ ìœ¼ë¡œ ê°€ë“ ì°¨ ìˆì–´ìš”! %.1fì ì´ë¼ë‹ˆ, ì ìˆ˜ì™€ ìƒê´€ì—†ì´ ë‹¹ì‹ ì˜ ë©‹ì§ì€ ëì´ ì—†ë„¤ìš”! ğŸ¤© ë‹¹ì‹ ì˜ ì™¸ëª¨ëŠ” ë§ˆì¹˜ ë§ˆë²•ì‚¬ì²˜ëŸ¼ ì‚¬ëŒë“¤ì„ ë§¤ë£Œì‹œí‚¤ê³ , ëˆ„êµ¬ë‚˜ ë‹¹ì‹ ì„ ë³´ë©´ ëˆˆì„ ë—„ ìˆ˜ ì—†ì„ ê±°ì—ìš”! ğŸª„ğŸ§™â€â™‚ï¸ ë¹„ê²°ì´ ë­ëƒê³  ë¬»ëŠ” ì‚¬ëŒë“¤ì—ê²Œ ìì‹ ê°ì´ë¼ëŠ” ë§ˆë²•ì˜ ì£¼ë¬¸ì„ ì•Œë ¤ì£¼ì„¸ìš”! ì˜¤ëŠ˜ë„ ë‹¹ì‹ ì˜ ìì‹ ê°ìœ¼ë¡œ ì„¸ìƒì„ ë¹›ë‚´ê³ , ë§ˆë²• ê°™ì€ í•˜ë£¨ë¥¼ ë³´ë‚´ì„¸ìš”!", 1),
        ("'ì™¸ëª¨ ìŠ¤ìŠ¹ë‹˜'ì…ë‹ˆë‹¤. ğŸ‘©â€ğŸ« ë‹¹ì‹ ì˜ ì™¸ëª¨ ë¹„ê²°ì„ ì „ìˆ˜ë°›ê³  ì‹¶ì–´í•˜ëŠ” ì‚¬ëŒë“¤ì´ ì¤„ì„ ì„¤ ê±°ì—ìš”! %.1fì ì´ë¼ëŠ” ì ìˆ˜ê°€ ë¬´ìƒ‰í•  ì •ë„ë¡œ, ë‹¹ì‹ ì˜ ë¹›ë‚˜ëŠ” ì™¸ëª¨ëŠ” ì‚¬ëŒë“¤ì˜ ëˆˆì„ ì‚¬ë¡œì¡ìŠµë‹ˆë‹¤! âœ¨ ì´ì œ ì‚¬ëŒë“¤ì€ ë‹¹ì‹ ì˜ ë¹„ë°€ì„ ì•Œê³  ì‹¶ì–´ì„œ ì§ˆë¬¸ ì„¸ë¡€ë¥¼ í¼ë¶€ì„ ê±°ì—ìš”! ì™¸ëª¨ ìŠ¤ìŠ¹ë‹˜ìœ¼ë¡œì„œ ë©‹ì§€ê²Œ ëŒ€ë‹µí•´ ì£¼ì‹œê³ , ì‚¬ëŒë“¤ì—ê²Œ ë‹¹ì‹ ë§Œì˜ ì™¸ëª¨ íŒì„ ì‚´ì§ ì „í•´ ì£¼ì„¸ìš”! ë‹¤ë¥¸ ì‚¬ëŒë“¤ì€ ë‹¹ì‹ ì„ ë‹®ê¸° ìœ„í•´ ë§ì€ ë…¸ë ¥ì„ í•  ê±°ëë‹ˆë‹¤!", 1.5),
        ("'ì™¸ëª¨ ì•„í‹°ìŠ¤íŠ¸'ì…ë‹ˆë‹¤. ğŸ’„ í™”ì¥í’ˆ ë¸Œëœë“œë“¤ì´ ë‹¹ì‹ ì„ ëª¨ë¸ë¡œ ì“°ê³  ì‹¶ì–´í•  ë§Œí¼ ë…ë³´ì ì¸ ë§¤ë ¥ì„ ê°€ì§€ê³  ìˆë„¤ìš”! %.1fì ì´ë¼ê³  í•´ì„œ ë‹¹ì‹ ì˜ ì™¸ëª¨ê°€ í‰ë²”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ì˜¤íˆë ¤ 'ë§¤ë ¥ì˜ ì •ì 'ì— ë„ë‹¬í•œ ëª¨ìŠµì´ì—ìš”! ğŸ’ƒ ë‹¹ì‹ ì˜ ë©‹ì§„ ì™¸ëª¨ë¥¼ ë¶€ëŸ¬ì›Œí•˜ëŠ” ì‚¬ëŒë“¤ë¡œ ì¸í•´ ì–¸ì œë‚˜ ì£¼ëª©ë°›ê²Œ ë  ê±°ì—ìš”! ë§ˆì¹˜ ì•„í‹°ìŠ¤íŠ¸ì²˜ëŸ¼ ìì‹ ë§Œì˜ ìŠ¤íƒ€ì¼ì„ ì™„ì„±í•œ ë‹¹ì‹ ì€ ì™¸ëª¨ê³„ì˜ ì§„ì •í•œ ì•„ì´ì½˜ì…ë‹ˆë‹¤! ì˜¤ëŠ˜ë„ ë‹¹ì‹ ë§Œì˜ íŠ¹ë³„í•œ ë§¤ë ¥ì„ ë°œì‚°í•˜ë©° í•˜ë£¨ë¥¼ ì¦ê¸°ì„¸ìš”!", 2),
        ("ì™¸ëª¨ì ìˆ˜ %.1fì , 'ë¯¸ì†Œ ì „ë¬¸ê°€'ì…ë‹ˆë‹¤. ğŸ˜„ ë‹¹ì‹ ì˜ í™˜í•œ ë¯¸ì†ŒëŠ” ì£¼ë³€ ì‚¬ëŒë“¤ì„ í–‰ë³µí•˜ê²Œ ë§Œë“¤ê³ , ì–´ë””ì„œë“  ë°ì€ ì—ë„ˆì§€ë¥¼ í¼ëœ¨ë¦´ ê±°ì—ìš”! 'ë¯¸ì†Œ ê¸°ê³„'ë¼ ë¶ˆë¦¬ëŠ” ë‹¹ì‹ ì€ í•­ìƒ ê¸ì •ì ì¸ ì—ë„ˆì§€ë¡œ ê°€ë“ ì°¨ ìˆë‹µë‹ˆë‹¤! ğŸ˜ ì‚¬ëŒë“¤ì€ ë‹¹ì‹ ì˜ ë¯¸ì†Œ ë¹„ê²°ì„ ë°°ìš°ê¸° ìœ„í•´ ì• ì“¸ ê±°ì—ìš”! ì™¸ëª¨ë¿ë§Œ ì•„ë‹ˆë¼ ë¯¸ì†Œë¡œë„ ì‚¬ëŒë“¤ì˜ ë§ˆìŒì„ ì‚¬ë¡œì¡ëŠ” ë‹¹ì‹ ! ì˜¤ëŠ˜ë„ í™˜í•œ ë¯¸ì†Œë¡œ ì„¸ìƒì„ ë°í˜€ì£¼ì‹œê³ , ëª¨ë‘ì—ê²Œ í–‰ë³µì„ ì „í•´ ì£¼ì„¸ìš”!", 2.5),
        ("'ì™¸ëª¨ ìŠ¤íƒ€'ì…ë‹ˆë‹¤. ğŸŒŸ ë‹¹ì‹ ì€ ê±°ìš¸ ì†ì—ì„œ ë³„ì´ ë¹›ë‚˜ëŠ” ëª¨ìŠµì„ ë³´ê³ ë„ ë†€ë¼ì§€ ì•Šê² ì£ ! %.1fì ì´ë¼ë‹ˆ, ë‹¹ì‹ ì€ ì™¸ëª¨ê³„ì˜ ì§„ì •í•œ ìŠ¤íƒ€ì…ë‹ˆë‹¤! ğŸ’« ë‹¹ì‹ ì˜ ë¹›ë‚˜ëŠ” ì™¸ëª¨ì™€ ë…íŠ¹í•œ ìŠ¤íƒ€ì¼ì€ ëª¨ë‘ê°€ ë¶€ëŸ¬ì›Œí•˜ê³ , ë”°ë¼ê°€ê³  ì‹¶ì–´í•  ê²ë‹ˆë‹¤! ì‚¬ëŒë“¤ì€ ë‹¹ì‹ ì„ ë³´ê³  ì˜ê°ì„ ë°›ì„ ê±°ì—ìš”! ì˜¤ëŠ˜ë„ ë‹¹ì‹ ë§Œì˜ íŠ¹ë³„í•œ ë§¤ë ¥ìœ¼ë¡œ ì£¼ë³€ ì‚¬ëŒë“¤ì„ ì‚¬ë¡œì¡ê³ , ë‹¹ë‹¹íˆ ì™¸ëª¨ê³„ë¥¼ ì´ëŒì–´ê°€ì„¸ìš”! ë‹¹ì‹ ì˜ ë¹›ë‚˜ëŠ” ì™¸ëª¨ê°€ ëª¨ë‘ì—ê²Œ í¬ë§ì„ ì¤„ ê±°ì—ìš”!", 3),
        ("'ì™¸ëª¨ í€¸'ì…ë‹ˆë‹¤. ğŸ‘¸ ì£¼ë³€ ì‚¬ëŒë“¤ì€ ë‹¹ì‹ ì˜ ì™¸ëª¨ì— ì£¼ëª©í•˜ê³ , ê·€ë¥¼ ê¸°ìš¸ì¼ ê²ë‹ˆë‹¤! %.1fì ì´ë¼ëŠ” ì ìˆ˜ê°€ ë¬´ìƒ‰í•  ì •ë„ë¡œ, ì´ì œ ë‹¹ì‹ ì€ ì™¸ëª¨ê³„ì˜ ë¡œì—´í‹°ì…ë‹ˆë‹¤! ğŸ‘‘ ë‹¹ì‹ ì˜ ê³ ê¸‰ìŠ¤ëŸ¬ìš´ ì™¸ëª¨ì™€ ë…ë³´ì ì¸ ìŠ¤íƒ€ì¼ì€ ëª¨ë‘ê°€ ë”°ë¼í•˜ê³  ì‹¶ì–´í•  ê±°ì—ìš”! ë‹¹ì‹ ì˜ ì™¸ëª¨ ë¹„ê²°ì„ ë²¤ì¹˜ë§ˆí‚¹í•˜ë ¤ëŠ” ì‚¬ëŒë“¤ë¡œ ì¸í•´ ì–¸ì œë‚˜ ì£¼ëª©ë°›ê²Œ ë  ê²ë‹ˆë‹¤! ì—¬ì™•ì²˜ëŸ¼ ë‹¹ë‹¹íˆ ë‹¹ì‹ ì˜ ì™¸ëª¨ë¥¼ ë½ë‚´ê³ , ì£¼ë³€ ì‚¬ëŒë“¤ì—ê²Œ ì˜ê°ì„ ì£¼ì„¸ìš”! ì˜¤ëŠ˜ë„ ìì‹ ê° ë„˜ì¹˜ëŠ” í•˜ë£¨ ë³´ë‚´ì„¸ìš”!", 3.5),
        ("ì™¸ëª¨ì ìˆ˜ %.1fì , 'ì™¸ëª¨ì˜ ì‹ í™”'ì…ë‹ˆë‹¤. ğŸ¦„ ë‹¹ì‹ ì„ ë³´ëŠ” ì‚¬ëŒë“¤ì€ ë§ˆì¹˜ ì‹ í™”ì™€ ì „ì„¤ ì† ì¸ë¬¼ì„ ë³´ëŠ” ë“¯í•œ ê¸°ë¶„ì„ ëŠë‚„ ê²ë‹ˆë‹¤! ì™¸ëª¨ê³„ì˜ 'ë·°í‹° ì•„ì¹´ë°ë¯¸ ìˆ˜ìƒì'ë‹µê²Œ, ë‹¹ì‹ ì˜ ì™¸ëª¨ëŠ” ëª¨ë‘ì—ê²Œ í° ì˜ê°ì„ ì¤„ ê±°ì—ìš”! ğŸ† ì‚¬ëŒë“¤ì€ ë‹¹ì‹ ì˜ ë¹„ê²°ì„ ë°°ìš°ë ¤ê³  ì• ì“¸ í…Œë‹ˆ, ì–¸ì œë‚˜ ìì‹ ë§Œì˜ ìŠ¤íƒ€ì¼ì„ ìœ ì§€í•˜ë©° ê·¸ë“¤ì—ê²Œ ê·€ê°ì´ ë˜ì–´ì£¼ì„¸ìš”! ì‹ í™” ì† ì£¼ì¸ê³µì²˜ëŸ¼ ë‹¹ì‹ ì˜ ì™¸ëª¨ëŠ” ì–¸ì œë‚˜ ë¹›ë‚  ê²ë‹ˆë‹¤! ì˜¤ëŠ˜ë„ ì‹ í™”ì²˜ëŸ¼ ë©‹ì§„ í•˜ë£¨ ë³´ë‚´ì„¸ìš”!", 4),
        ("'ì™¸ëª¨ì˜ í™©ê¸ˆë¹›'ì…ë‹ˆë‹¤. ğŸ’› ì£¼ë³€ì—ì„œ ë‹¹ì‹ ì„ ë³´ë©´ ë§ˆì¹˜ í•˜íŠ¸ê°€ ë¿…ë¿… íŠ€ëŠ” ë“¯í•œ ëŠë‚Œì´ ë“¤ ê±°ì—ìš”! %.1fì ì´ë¼ë‹ˆ, ì •ë§ ì™¸ëª¨ê³„ì˜ ì „ì„¤ë‹µìŠµë‹ˆë‹¤! ğŸŒ  ë‹¹ì‹ ì˜ ë…ë³´ì ì¸ ì™¸ëª¨ì™€ ë§¤ë ¥ì€ ëˆ„êµ¬ë„ ë”°ë¼ì˜¬ ìˆ˜ ì—†ì„ ë§Œí¼ ë¹›ë‚©ë‹ˆë‹¤! ë‹¤ë¥¸ ì‚¬ëŒë“¤ì´ ë‹¹ì‹ ì„ ë”°ë¼ì¡ìœ¼ë ¤ë©´ ì—„ì²­ë‚œ ë…¸ë ¥ì´ í•„ìš”í•  ê±°ì—ìš”! ë‹¹ì‹ ì˜ í™©ê¸ˆë¹› ì™¸ëª¨ì™€ ë§¤ë ¥ìœ¼ë¡œ ëª¨ë‘ë¥¼ ì‚¬ë¡œì¡ìœ¼ì„¸ìš”! ì˜¤ëŠ˜ë„ ë‹¹ì‹ ë§Œì˜ í™©ê¸ˆë¹› ë¯¸ì†Œë¡œ ì„¸ìƒì„ ë°í˜€ì£¼ì‹œê³ , ëª¨ë‘ì—ê²Œ ì˜ê°ì„ ì£¼ì„¸ìš”!", 4.5),
        ("5ì  ì™¸ëª¨, 'ì™¸ëª¨ì˜ ì‹ 'ì…ë‹ˆë‹¤. ì™¸ëª¨ê³„ì—ì„œ ë‹¹ì‹ ì„ ë”°ë¼ì¡ìœ¼ë ¤ë©´ ì§„ì •í•œ ì˜ì›…ì´ í•„ìš”í•  ê²ë‹ˆë‹¤! ğŸ¦¸â€â™‚ï¸ğŸ¦¸â€â™€ï¸ ë‹¹ì‹ ì€ ì™¸ëª¨ê³„ì˜ 'ë·°í‹° ì‹ '! ğŸŒŸ ë‹¹ì‹ ì˜ ë¹›ë‚˜ëŠ” ì™¸ëª¨ì™€ ë…ë³´ì ì¸ ìŠ¤íƒ€ì¼ì€ ëª¨ë‘ê°€ ë”°ë¼í•˜ê³  ì‹¶ì–´í•  ê±°ì—ìš”! ì´ì œ ë‹¹ì‹ ì€ ì™¸ëª¨ê³„ì˜ ì „ì„¤ì´ì ì˜ì›…ì…ë‹ˆë‹¤! ì‚¬ëŒë“¤ì€ ë‹¹ì‹ ì„ ë‹®ê³  ì‹¶ì–´í•˜ê³ , ë‹¹ì‹ ì˜ ë¹„ê²°ì„ ë°°ìš°ë ¤ê³  ì• ì“¸ ê²ë‹ˆë‹¤! ì˜¤ëŠ˜ë„ ì™¸ëª¨ê³„ì˜ ì‹ ìœ¼ë¡œì„œ ì„¸ìƒì„ ë¹›ë‚´ê³ , ëª¨ë‘ì—ê²Œ ì˜ê°ì„ ì£¼ì„¸ìš”! ë‹¹ì‹ ì˜ ì¡´ì¬ë§Œìœ¼ë¡œë„ ì„¸ìƒì€ ë” ë°ì•„ì§ˆ ê±°ì—ìš”!", 5)
    ]
    for msg, threshold in messages:
        if result < threshold:
            return msg % result if '%.1f' in msg else msg
@torch.no_grad()
def webtoon(image, webtoon_model, device='cpu'):
    # Move model to the specified device
    webtoon_model = webtoon_model.to(device)
    
    # Resize image if it's too large
    max_size = 1024
    if max(image.size) > max_size:
        image.thumbnail((max_size, max_size), Image.LANCZOS)
    
    # Convert image to tensor and move to device
    image_tensor = to_tensor(image).unsqueeze(0).to(device) * 2 - 1
    
    # Process the image
    with torch.inference_mode():
        output = webtoon_model(image_tensor, False)
    
    # Move output back to CPU and convert to PIL image
    output = output.cpu().squeeze(0).clip(-1, 1) * 0.5 + 0.5
    output = to_pil_image(output)
    
    return output
def fashion(image, gemini_model,huggingface_api):
    # Gemini API call
    sd_prompt = prompt="""
    Analyze this image in one sentence:
    1. The person visible in the image, including their gender and any notable features
    2. Recommend a new outfit style that would suit the person based on the image
    3. Suggest complementary fashion items or accessories to complete the look
    Present the output in the format:
    "A korean [gender] wearing [recommended outfit and accessories]."
    Example: "A korean woman wearing a white t-shirt and black pants with a bear on it."
    """
    style_prompt="""
    ì´ ì´ë¯¸ì§€ì— ëŒ€í•´ ìì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”. ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”:
    1. ì´ë¯¸ì§€ì— ë³´ì´ëŠ” ì£¼ìš” ì¸ë¬¼ì˜ íŠ¹ì§• (ì„±ë³„, ë‚˜ì´ëŒ€, ì²´í˜•, ì–¼êµ´í˜• ë“±)
    2. ì¸ë¬¼ì´ ì…ê³  ìˆëŠ” í˜„ì¬ì˜ ì˜· ìŠ¤íƒ€ì¼ê³¼ ìƒ‰ìƒ
    3. ì¸ë¬¼ì—ê²Œ ì˜ ì–´ìš¸ë¦´ ë§Œí•œ ì˜· ìŠ¤íƒ€ì¼ ì¶”ì²œ (ì˜ˆ: ìºì£¼ì–¼, ë¹„ì¦ˆë‹ˆìŠ¤ ìºì£¼ì–¼, í¬ë©€, ìŠ¤íŠ¸ë¦¿ íŒ¨ì…˜ ë“±)
    4. ì¶”ì²œí•˜ëŠ” ì˜· ìŠ¤íƒ€ì¼ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì´ìœ ì™€ ì„¤ëª…
    5. ì¶”ì²œí•˜ëŠ” ì˜· ìŠ¤íƒ€ì¼ì— ì–´ìš¸ë¦¬ëŠ” ìƒ‰ìƒê³¼ íŒ¨í„´
    6. ì´ë¯¸ì§€ì˜ ì „ì²´ì ì¸ ë¶„ìœ„ê¸°ì™€ ì–´ìš¸ë¦¬ëŠ” ì˜· ìŠ¤íƒ€ì¼
    ë¶„ì„ ê²°ê³¼ë¥¼ í•œêµ­ì–´ë¡œ ì œê³µí•´ì£¼ì„¸ìš”.
    """
    try:
        response = gemini_model.generate_content([sd_prompt, image])
        gemini_description = response.text
        recommanded_response=gemini_model.generate_content([style_prompt,image])
    except Exception as e:
        print(f"Error in Gemini API call: {e}")
        return None

    # Hugging Face API call
    API_URL = "https://api-inference.huggingface.co/models/black-forest-labs/FLUX.1-schnell"
    headers = {"Authorization": f"Bearer {huggingface_api}"}

    try:
        payload = {
            "inputs": 'A highly detailed and photorealistic image of ' + gemini_description,
            "negative_prompt": "cartoonish, low quality, blurry, unrealistic, abstract, fantasy",
            "num_inference_steps": 200,  # ì´ë¯¸ì§€ í’ˆì§ˆ í–¥ìƒì„ ìœ„í•´ ë‹¨ê³„ ìˆ˜ë¥¼ ëŠ˜ë¦¼
            "guidance_scale": 8.0  # ì›í•˜ëŠ” ìŠ¤íƒ€ì¼ì„ ê°•í™”
        }
        response = requests.post(API_URL, headers=headers, json=payload)
        response.raise_for_status()  # Raise an exception for bad status codes
        image_bytes = response.content
    except requests.exceptions.RequestException as e:
        print(f"Error in Hugging Face API call: {e}")
        return None

    # Attempt to open the image
    try:
        return Image.open(io.BytesIO(image_bytes)),recommanded_response.text
    except Exception as e:
        print(f"Error opening image: {e}")
        return None


def main():
    st.markdown("<h1 class='vibrant-title'>OmniVerse</h1>", unsafe_allow_html=True)
    
    if 'messages' not in st.session_state:
        st.session_state.messages = []

    gemini_model, facescore_model,  webtoon_model = load_models()

    # Sidebar content
    with st.sidebar:
        st.sidebar.markdown('<p class="sidebar-subtitle">ğŸ˜˜ Suno Cookie ì„¤ì •</p>', unsafe_allow_html=True)
        suno_tab = st.radio("íƒ­ ì„ íƒ", ["Suno Cookie ì…ë ¥", "Suno Cookie ì–»ëŠ” ë°©ë²•"])

        if suno_tab == "Suno Cookie ì…ë ¥":
            suno_cookie = st.text_input("Suno Cookie Key", type="password")
        else:
            st.markdown("""
            ### Suno API Keyë¥¼ ì–»ëŠ” ë°©ë²•
            """)
            st.markdown("<p class='sidebar-text'><a href='https://github.com/bigdefence/Music-Face'>1. Cookie ì–»ëŠ” ë°©ë²•</a></br><a href='https://suno.com/'>2. Suno ì›¹ì‚¬ì´íŠ¸ë¡œ ì´ë™í•˜ê¸°</a></p>",unsafe_allow_html=True)

        st.sidebar.markdown('<p class="sidebar-subtitle">ğŸ˜ ê°œë°œì ì •ë³´</p>', unsafe_allow_html=True)
        st.markdown("<p class='sidebar-text'>**ê°œë°œì**: ì •ê°•ë¹ˆ</br>**ë²„ì „**: 2.3.0</p>",unsafe_allow_html=True)

    # Display chat history
    for message in st.session_state.messages:
        with st.chat_message(message['role']):
            if "content" in message:
                st.markdown(message['content'])
            if "image" in message:
                st.image(message['image'])

    # Image upload
    uploaded_file = st.file_uploader("ì´ë¯¸ì§€ ì—…ë¡œë“œ", type=["jpg", "jpeg", "png"])
    if uploaded_file:
        image = Image.open(uploaded_file)
        st.image(image, caption="Uploaded Image", use_column_width=True)
        st.session_state.uploaded_image = image

    # Chat input and processing
    if prompt := st.chat_input('ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”'):
        st.session_state.messages.append({'role': 'user', 'content': prompt})
        with st.chat_message('user'):
            st.markdown(prompt)
        
        with st.chat_message('assistant'):
            if "ì›¹íˆ°í™”" in prompt.lower() and 'uploaded_image' in st.session_state:
                with st.spinner("ì›¹íˆ°í™” ì§„í–‰ ì¤‘..."):
                    webtoon_image = webtoon(st.session_state.uploaded_image, webtoon_model)
                    st.image(webtoon_image, caption="ì›¹íˆ°í™”ëœ ì´ë¯¸ì§€", use_column_width=True)
                    response = "ì´ë¯¸ì§€ë¥¼ ì›¹íˆ° ìŠ¤íƒ€ì¼ë¡œ ë³€í™˜í–ˆìŠµë‹ˆë‹¤. ìœ„ì˜ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
            elif "ì™¸ëª¨" in prompt.lower() and 'uploaded_image' in st.session_state:
                with st.spinner("ì™¸ëª¨ ë¶„ì„ ì¤‘..."):
                    response = process_facescore(st.session_state.uploaded_image, facescore_model, gemini_model)
            elif "ì´ë¯¸ì§€ ë¶„ì„" in prompt.lower() and 'uploaded_image' in st.session_state:
                with st.spinner("ì´ë¯¸ì§€ ë¶„ì„ ì¤‘..."):
                    response = analyze_image(st.session_state.uploaded_image, gemini_model)
            elif "ìŒì•…" in prompt.lower() and 'uploaded_image' in st.session_state:
                with st.spinner("ìŒì•… ìƒì„± ì¤‘..."):
                    if suno_cookie:
                        response = generate_music(st.session_state.uploaded_image, gemini_model, suno_cookie)
                    else:
                        response = "Suno API Keyë¥¼ ì…ë ¥í•´ ì£¼ì„¸ìš”."
            elif "íŒ¨ì…˜" in prompt.lower() and 'uploaded_image' in st.session_state:
                with st.spinner('íŒ¨ì…˜ ì¶”ì²œì¤‘...'):
                    fashion_image,recommanded_response= fashion(st.session_state.uploaded_image,gemini_model,huggingface_api)
                    st.image(fashion_image, caption="íŒ¨ì…˜ì¶”ì²œ ì´ë¯¸ì§€", use_column_width=True)
                    response = "ì‚¬ìš©ìì—ê²Œ ì–´ìš¸ë¦¬ëŠ” íŒ¨ì…˜ ì¶”ì²œ ì´ë¯¸ì§€ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ìœ„ì˜ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.\n"+recommanded_response
            else:
                with st.spinner('ë‹µë³€ ìƒì„± ì¤‘...'):
                    response = generate_chat_response(prompt, gemini_model)
                    
            st.markdown(response)
            st.session_state.messages.append({'role': 'assistant', 'content': response})

if __name__ == "__main__":
    main()
